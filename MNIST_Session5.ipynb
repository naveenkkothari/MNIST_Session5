{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2IX8_Rh_XxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sGju60hfQFWL"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 16, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(32, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "c0XnCoucQsFu"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", use_cuda)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FlhBDVBQ021",
        "outputId": "7f8e91dd-9606-4c25-805b-20dc6948239c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "CUDA Available? True\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             160\n",
            "              ReLU-2           [-1, 16, 28, 28]               0\n",
            "       BatchNorm2d-3           [-1, 16, 28, 28]              32\n",
            "            Conv2d-4           [-1, 16, 26, 26]           2,320\n",
            "              ReLU-5           [-1, 16, 26, 26]               0\n",
            "       BatchNorm2d-6           [-1, 16, 26, 26]              32\n",
            "         MaxPool2d-7           [-1, 16, 13, 13]               0\n",
            "           Dropout-8           [-1, 16, 13, 13]               0\n",
            "            Conv2d-9           [-1, 16, 13, 13]           2,320\n",
            "             ReLU-10           [-1, 16, 13, 13]               0\n",
            "      BatchNorm2d-11           [-1, 16, 13, 13]              32\n",
            "           Conv2d-12           [-1, 32, 13, 13]           4,640\n",
            "             ReLU-13           [-1, 32, 13, 13]               0\n",
            "      BatchNorm2d-14           [-1, 32, 13, 13]              64\n",
            "           Conv2d-15             [-1, 16, 7, 7]           4,624\n",
            "             ReLU-16             [-1, 16, 7, 7]               0\n",
            "      BatchNorm2d-17             [-1, 16, 7, 7]              32\n",
            "        MaxPool2d-18             [-1, 16, 3, 3]               0\n",
            "          Dropout-19             [-1, 16, 3, 3]               0\n",
            "           Conv2d-20             [-1, 32, 3, 3]           4,640\n",
            "             ReLU-21             [-1, 32, 3, 3]               0\n",
            "      BatchNorm2d-22             [-1, 32, 3, 3]              64\n",
            "        MaxPool2d-23             [-1, 32, 1, 1]               0\n",
            "          Dropout-24             [-1, 32, 1, 1]               0\n",
            "           Linear-25                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 19,290\n",
            "Trainable params: 19,290\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.79\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 0.87\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 16\n",
        "SEED = 1\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "batch_size = 16\n",
        "classes = range(10)\n",
        "train = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "#train_loader = torch.utils.data.DataLoader(dataset=train,batch_size=batch_size,shuffle = True)\n",
        "\n",
        "#test_loader  = torch.utils.data.DataLoader(dataset=test,batch_size=batch_size,shuffle = False)\n"
      ],
      "metadata": {
        "id": "f-QZfKpsRBpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb16052-543e-4200-ed22-3261c2d7f01a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_data, batch_label = next(iter(train))\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(12):\n",
        "  plt.subplot(3,4,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n",
        "  plt.title(batch_label[i].item())\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "efd0fT6tSqMP",
        "outputId": "d5851b2b-ee2b-47e0-bafc-3cc99940c799"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = torch.stack([img for img, _ in train], dim=0)\n",
        "flattened_images = all_images.view(-1)\n",
        "mean = flattened_images.mean()\n",
        "std = flattened_images.std()\n",
        "print(f\"Mean of MNIST dataset: {mean.item():.4f}\")\n",
        "print(f\"Standard deviation of MNIST dataset: {std.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKL45tiAVAOj",
        "outputId": "457300d5-c602-405b-fa7b-3341d7a39852"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of MNIST dataset: -0.0001\n",
            "Standard deviation of MNIST dataset: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "criterion = nn.NLLLoss()   # with log_softmax() as the last layer, this is equivalent to cross entropy loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "-vakYsIXRKhv"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "110phRdMa7zl",
        "outputId": "6e67046c-8594-4d4c-9c6d-562d94fb9336"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Time!\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# Some initialization work first...\n",
        "epochs = 20\n",
        "train_losses, val_losses = [], []\n",
        "train_accu, val_accu = [], []\n",
        "start_time = time.time()\n",
        "early_stop_counter = 10   # stop when the validation loss does not improve for 10 iterations to prevent overfitting\n",
        "counter = 0\n",
        "best_val_loss = float('Inf')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for e in range(epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    running_loss = 0\n",
        "    accuracy=0\n",
        "    # training step\n",
        "    model.train()\n",
        "    for images, labels in train:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        log_ps = model(images)\n",
        "\n",
        "        ps = torch.exp(log_ps)\n",
        "        top_p, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # record training loss and error, then evaluate using validation data\n",
        "    train_losses.append(running_loss/len(train))\n",
        "    train_accu.append(accuracy/len(train))\n",
        "    val_loss = 0\n",
        "    accuracy=0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            log_ps = model(images)\n",
        "            val_loss += criterion(log_ps, labels)\n",
        "\n",
        "            ps = torch.exp(log_ps)\n",
        "            top_p, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "    val_losses.append(val_loss/len(test))\n",
        "    val_accu.append(accuracy/len(test))\n",
        "\n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "          \"Time: {:.2f}s..\".format(time.time()-epoch_start_time),\n",
        "          \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
        "          \"Training Accu: {:.3f}.. \".format(train_accu[-1]),\n",
        "          \"Val Loss: {:.3f}.. \".format(val_losses[-1]),\n",
        "          \"Val Accu: {:.3f}\".format(val_accu[-1]))\n",
        "\n",
        "#     print('Epoch %d / %d took %6.2f seconds' % (e+1, epochs, time.time()-epoch_start_time))\n",
        "#     print('Total training time till this epoch was %8.2f seconds' % (time.time()-start_time))\n",
        "\n",
        "    if val_losses[-1] < best_val_loss:\n",
        "        best_val_loss = val_losses[-1]\n",
        "        counter=0\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    else:\n",
        "        counter+=1\n",
        "        print('Validation loss has not improved since: {:.3f}..'.format(best_val_loss), 'Count: ', str(counter))\n",
        "        if counter >= early_stop_counter:\n",
        "            print('Early Stopping Now!!!!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPdnIZEm7n7G",
        "outputId": "ec9e24a2-cc71-4fb3-b77a-3437141fddf4"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/20..  Time: 42.39s.. Training Loss: 0.968..  Training Accu: 0.699..  Val Loss: 0.160..  Val Accu: 0.959\n",
            "Epoch: 2/20..  Time: 41.32s.. Training Loss: 0.261..  Training Accu: 0.928..  Val Loss: 0.080..  Val Accu: 0.976\n",
            "Epoch: 3/20..  Time: 42.31s.. Training Loss: 0.173..  Training Accu: 0.952..  Val Loss: 0.054..  Val Accu: 0.982\n",
            "Epoch: 4/20..  Time: 42.38s.. Training Loss: 0.132..  Training Accu: 0.962..  Val Loss: 0.043..  Val Accu: 0.985\n",
            "Epoch: 5/20..  Time: 41.68s.. Training Loss: 0.110..  Training Accu: 0.969..  Val Loss: 0.043..  Val Accu: 0.986\n",
            "Validation loss has not improved since: 0.043.. Count:  1\n",
            "Epoch: 6/20..  Time: 42.57s.. Training Loss: 0.098..  Training Accu: 0.972..  Val Loss: 0.036..  Val Accu: 0.988\n",
            "Epoch: 7/20..  Time: 41.59s.. Training Loss: 0.088..  Training Accu: 0.975..  Val Loss: 0.035..  Val Accu: 0.988\n",
            "Epoch: 8/20..  Time: 41.69s.. Training Loss: 0.081..  Training Accu: 0.976..  Val Loss: 0.029..  Val Accu: 0.990\n",
            "Epoch: 9/20..  Time: 41.79s.. Training Loss: 0.074..  Training Accu: 0.979..  Val Loss: 0.029..  Val Accu: 0.990\n",
            "Epoch: 10/20..  Time: 42.42s.. Training Loss: 0.068..  Training Accu: 0.981..  Val Loss: 0.028..  Val Accu: 0.991\n",
            "Epoch: 11/20..  Time: 42.29s.. Training Loss: 0.065..  Training Accu: 0.981..  Val Loss: 0.027..  Val Accu: 0.990\n",
            "Epoch: 12/20..  Time: 41.32s.. Training Loss: 0.062..  Training Accu: 0.981..  Val Loss: 0.023..  Val Accu: 0.992\n",
            "Epoch: 13/20..  Time: 41.41s.. Training Loss: 0.059..  Training Accu: 0.983..  Val Loss: 0.025..  Val Accu: 0.992\n",
            "Validation loss has not improved since: 0.023.. Count:  1\n",
            "Epoch: 14/20..  Time: 41.77s.. Training Loss: 0.055..  Training Accu: 0.984..  Val Loss: 0.023..  Val Accu: 0.992\n",
            "Epoch: 15/20..  Time: 41.31s.. Training Loss: 0.052..  Training Accu: 0.984..  Val Loss: 0.024..  Val Accu: 0.992\n",
            "Validation loss has not improved since: 0.023.. Count:  1\n",
            "Epoch: 16/20..  Time: 42.86s.. Training Loss: 0.054..  Training Accu: 0.984..  Val Loss: 0.020..  Val Accu: 0.993\n",
            "Epoch: 17/20..  Time: 41.23s.. Training Loss: 0.050..  Training Accu: 0.985..  Val Loss: 0.022..  Val Accu: 0.993\n",
            "Validation loss has not improved since: 0.020.. Count:  1\n",
            "Epoch: 18/20..  Time: 41.22s.. Training Loss: 0.048..  Training Accu: 0.985..  Val Loss: 0.021..  Val Accu: 0.993\n",
            "Validation loss has not improved since: 0.020.. Count:  2\n",
            "Epoch: 19/20..  Time: 41.84s.. Training Loss: 0.049..  Training Accu: 0.986..  Val Loss: 0.022..  Val Accu: 0.992\n",
            "Validation loss has not improved since: 0.020.. Count:  3\n",
            "Epoch: 20/20..  Time: 41.27s.. Training Loss: 0.048..  Training Accu: 0.986..  Val Loss: 0.021..  Val Accu: 0.993\n",
            "Validation loss has not improved since: 0.020.. Count:  4\n"
          ]
        }
      ]
    }
  ]
}